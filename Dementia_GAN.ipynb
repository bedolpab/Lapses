{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338e80fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from skimage import io\n",
    "from skimage.io import imread_collection\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cae80d",
   "metadata": {},
   "source": [
    "## Fetch Data (Images)\n",
    "We begin by fetching a dataset of 10,000 images from [thispersondoesnotexistcom](https://www.thispersondoesnotexist.com). We do so by requesting from the endpoint `thispersondoesnotexist.com/images` 10,000 (k) times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b5767",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefbd236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(image, count):\n",
    "        with open(f'{image_path}/img_{count}.png', 'wb') as f:\n",
    "            f.write(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71888d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_images(k: int, folder_name: str):\n",
    "    \"\"\" \n",
    "    Fetch images from thispersondoesnotexist.com\n",
    "    \n",
    "    :param k: number of images to fetch\n",
    "    :param folder_name: name of folder to save images to\n",
    "    \"\"\"\n",
    "    if k < 1:\n",
    "        return 0\n",
    "    \n",
    "    # Locals\n",
    "    count = 0\n",
    "    endpoint = 'image'\n",
    "    url = f'https://thispersondoesnotexist.com/{endpoint}'\n",
    "    while count < k:\n",
    "        image = requests.get(url).content\n",
    "        save_image(image)\n",
    "        count += 1\n",
    "        \n",
    "        # A time.sleep(x) is recommended to avoid latency errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5865ccc",
   "metadata": {},
   "source": [
    "We can now call this function and store the images locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbe2a26",
   "metadata": {},
   "source": [
    "```python\n",
    "fetch_images(k=10_000, folder_name='images')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1147f81",
   "metadata": {},
   "source": [
    "## Validating image\n",
    "We should validate wether the image exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f337f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(folder_name:str, idx:int) -> IMAGE_TYPE:\n",
    "    return io.imread(f'{folder_name}/img_{idx}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a623c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_exists(folder_name:str) -> bool:\n",
    "    \"\"\" \n",
    "    Check whether an image exists in folder_name\n",
    "    \n",
    "    :param folder_name: folder in which dataset images are located\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Default image 0\n",
    "        image = read_image(image_path, 0)\n",
    "        return True\n",
    "    except:\n",
    "        print(f'Image \"img_0.png\" in {folder_name} not found')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66348ebe",
   "metadata": {},
   "source": [
    "## Showing a batch\n",
    "We can see a random batch of images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(batch):\n",
    "    images = np.random.randint(low=0, high=len(batch), size=16) # get random indices\n",
    "    fig = plt.figure(figsize= (4, 4)) \n",
    "    fig, axs = plt.subplots(4,4, sharex=True, sharey=True)\n",
    "    cnt = 0 \n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            axs[i, j].imshow(batch[images[cnt]]) # get image from batch at index 'i'\n",
    "            cnt += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5374b4f3",
   "metadata": {},
   "source": [
    "### Image Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204529ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_attr(batch):\n",
    "    print(f'Images are {batch[0].shape[0]} by {batch[0].shape[1]} with {batch[0].shape[2]} channels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076b6da8",
   "metadata": {},
   "source": [
    "Retreive all images from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80adab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_collection(folder_name:str):\n",
    "    return imread_collection(f'{folder_name}/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = read_collection(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e7510b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc84282",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3218f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e68627",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_attr(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4762074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(collection[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea824760",
   "metadata": {},
   "source": [
    "### Resizing Images\n",
    "As we can see, all images fetched are $1024 \\times 1024 \\times 3$, it is necessary we resize these into smaller dimensions to efficiently approach this DCGAN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5635add",
   "metadata": {},
   "source": [
    "We import `CV2` to resize the images in `./images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52646ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae67684",
   "metadata": {},
   "source": [
    "We now resize every image in the `collection` and update them with given the new dimensions. All images in `collection` are named as their appropriate index in this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf1f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(collection)):\n",
    "    img = cv2.resize(collection[i], dsize=(512, 512), interpolation=cv2.INTER_CUBIC)\n",
    "    new_image = Image.fromarray(img)\n",
    "    new_image.save(f'{image_path}/img_{i}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159fdb0",
   "metadata": {},
   "source": [
    "### Neural Network - 1.0\n",
    "We begin by definning attributes. All images in the dataset are from [thispersondoesnotexistcom](https://www.thispersondoesnotexist.com), therefore all images are $1024 \\times 1024$ with $3$ channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e13c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = collection[0].shape[0]\n",
    "cols = collection[0].shape[1]\n",
    "channels = collection[0].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65468597",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (rows, cols, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963eae70",
   "metadata": {},
   "source": [
    "`z_dim` represents the dimenions of the noise vector to be inputed into the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7253c8b7",
   "metadata": {},
   "source": [
    "We first import libraries to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a6545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Reshape, Conv2DTranspose, UpSampling2D, Activation, Conv2D, BatchNormalization, UpSampling2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 512 # 512 is a good default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9138c4b2",
   "metadata": {},
   "source": [
    "We implement the schematics for $G(z)$ to generate $1024 \\times 1024$ images from [Marchesi, Marco. (2017). Megapixel Size Image Creation using Generative Adversarial Networks.](https://www.researchgate.net/publication/317300265_Megapixel_Size_Image_Creation_using_Generative_Adversarial_Networks), [Karras, Aila. (2018). Progressive Growing of GANs for Improved Quality Stability, and Variation.](https://arxiv.org/pdf/1710.10196.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934dc84d",
   "metadata": {},
   "source": [
    "#### Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacfba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_png(model, file_name:str):\n",
    "    plot_model(model, to_file=f'{file_name}.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d72fe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(z):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input Latent vector\n",
    "    model.add(Dense(1*1*512, input_dim=z))\n",
    "    model.add(Reshape((1, 1, 512)))\n",
    "    \n",
    "    # Conv 1.0 (4x4) -> LeakyReLU -> (3x3) -> LeakyReLU\n",
    "    model.add(Conv2DTranspose(512, kernel_size=4, padding='valid'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2DTranspose(512, kernel_size=3, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Conv 2.0 (3x3) -> LeakyReLU -> (3x3) -> LeakyReLU\n",
    "    model.add(Conv2DTranspose(512, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2DTranspose(512, kernel_size=3, padding='same')) \n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Conv 3.0 (3x3) -> LeakyReLU -> (3x3) -> LeakyReLU\n",
    "    model.add(Conv2DTranspose(512, kernel_size=3, strides=2, padding='same')) \n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2DTranspose(512, kernel_size=3, padding='same')) \n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Conv 4.0 (3x3) -> LeakyReLU -> (3x3) -> LeakyReLU\n",
    "    model.add(Conv2DTranspose(512, kernel_size=3, strides=2, padding='same')) \n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2DTranspose(512, kernel_size=3, padding='same')) \n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Conv 5.0 (3x3) -> LeakyReLU -> (3x3) -> LeakyReLU\n",
    "    model.add(Conv2DTranspose(512, kernel_size=3, strides=2, padding='same')) \n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2DTranspose(512, kernel_size=3, padding='same')) \n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Conv 6.0 (3x3) -> LeakyReLU -> (3x3) -> LeakyReLU\n",
    "    model.add(Conv2DTranspose(256, kernel_size=3, padding='same')) \n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2DTranspose(256, kernel_size=3, padding='same')) \n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Conv 7.0 (3x3) -> LeakyReLU -> (3x3) -> LeakyReLU\n",
    "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same')) \n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2DTranspose(128, kernel_size=3, padding='same')) \n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Conv 8.0 (3x3) -> LeakyReLU -> (3x3) -> LeakyReLU\n",
    "    model.add(Conv2DTranspose(64, kernel_size=3, strides=2, padding='same')) \n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=3, padding='same')) \n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Conv 9.0 (3x3) -> LeakyReLU -> (3x3) -> LeakyReLU\n",
    "    model.add(Conv2DTranspose(32, kernel_size=3, strides=2, padding='same')) \n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2DTranspose(32, kernel_size=3, padding='same')) \n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    \n",
    "    # Conv 10.0 (3x3) -> LeakyReLU -> (3x3) -> LeakyReLU\n",
    "    model.add(Conv2DTranspose(16, kernel_size=3, strides=2, padding='same')) \n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2DTranspose(16, kernel_size=3, padding='same')) \n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2DTranspose(3, kernel_size=1, padding='valid')) \n",
    "    model.add(Activation('tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb8f7e",
   "metadata": {},
   "source": [
    "We can test our generator's functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6526c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gen(z):\n",
    "    gen = create_generator(z)\n",
    "    noise = tf.random.normal([1, 512],)\n",
    "    img = gen(noise, training=False)\n",
    "    img = tf.reshape(img, shape=(img.shape[1], img.shape[2], img.shape[3]))\n",
    "    flat = tf.reshape(img, [-1]).numpy()\n",
    "    print(flat)\n",
    "    plt.hist(flat, range=(np.amin(flat),np.amax(flat)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cc68c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen(z=z_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6565f23b",
   "metadata": {},
   "source": [
    "#### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4350700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(3, kernel_size=1, padding='same', input_shape=img_shape))\n",
    "    model.add(Conv2D(3, kernel_size=3, padding='same', input_shape=img_shape))\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, padding='same', input_shape=img_shape))\n",
    "    \n",
    "    # Conv 2.0\n",
    "    model.add(Conv2D(32, kernel_size=3, padding='same', input_shape=img_shape))\n",
    "    model.add(Conv2D(64, kernel_size=2, strides=2, padding='valid', input_shape=img_shape))\n",
    "    \n",
    "    # Conv 3.0\n",
    "    model.add(Conv2D(64, kernel_size=3, padding='same', input_shape=img_shape))\n",
    "    model.add(Conv2D(128, kernel_size=2, strides=2, padding='valid', input_shape=img_shape))\n",
    "    \n",
    "    # Conv 4.0\n",
    "    model.add(Conv2D(256, kernel_size=3, padding='same', input_shape=img_shape))\n",
    "    model.add(Conv2D(256, kernel_size=2, strides=2, padding='valid', input_shape=img_shape))\n",
    "    \n",
    "    # Conv 5.0\n",
    "    model.add(Conv2D(512, kernel_size=3, padding='same', input_shape=img_shape))\n",
    "    model.add(Conv2D(512, kernel_size=2, strides=2, padding='valid', input_shape=img_shape))\n",
    "    \n",
    "    # Conv 6.0\n",
    "    model.add(Conv2D(512, kernel_size=3, padding='same', input_shape=img_shape))\n",
    "    model.add(Conv2D(512, kernel_size=2, strides=2, padding='valid', input_shape=img_shape))\n",
    "    \n",
    "    # Conv 7.0\n",
    "    model.add(Conv2D(512, kernel_size=3, padding='same', input_shape=img_shape))\n",
    "    model.add(Conv2D(512, kernel_size=2, strides=2, padding='valid', input_shape=img_shape))\n",
    "    \n",
    "    # Conv 8.0\n",
    "    model.add(Conv2D(512, kernel_size=3, padding='same', input_shape=img_shape))\n",
    "    model.add(Conv2D(512, kernel_size=2, strides=2, padding='valid', input_shape=img_shape))\n",
    "    \n",
    "    # Final \n",
    "    model.add(Conv2D(512, kernel_size=3, padding='same', input_shape=img_shape))\n",
    "    model.add(Conv2D(512, kernel_size=3, strides=2, padding='valid', input_shape=img_shape))\n",
    "    \n",
    "    # Finalized\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf2e86e",
   "metadata": {},
   "source": [
    "#### Set up (S) - 1.1 Create\n",
    "We begin by initializing the discriminator and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_generator(z=z_dim)\n",
    "discriminator = create_discriminator(img_shape=image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c354a60c",
   "metadata": {},
   "source": [
    "#### S - 1.2 Compile \n",
    "We know compile both models. <br>\n",
    "NOTE: _Implement OS exisitng model loading_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed9c599",
   "metadata": {},
   "source": [
    "##### Generator Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6894eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c608710b",
   "metadata": {},
   "source": [
    "##### Discriminator Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89913b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Adam(),\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d07b72",
   "metadata": {},
   "source": [
    "#### S - 1.3 Disable Discriminator Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7864a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2938b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(discriminator, to_file='discriminator.png', show_shapes=True, show_dtype=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f85a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(generator, to_file='generator.png', show_shapes=True, show_dtype=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f607b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAN(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130ff932",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a1150b",
   "metadata": {},
   "source": [
    "#### TESTING DISCRIMINATOR\n",
    "---\n",
    "```python\n",
    "noise = tf.random.normal([1, 512],)\n",
    "img = generator(noise, training=False)\n",
    "disc_output = discriminator(img, training=False)\n",
    "print(\"Discriminator output on fake images:\", disc_output.numpy())\n",
    "real_image = collection[0]\n",
    "disc_2_output = discriminator(np.expand_dims(real_image, axis=0), training=False)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913f37e",
   "metadata": {},
   "source": [
    "#### S - 1.4 Training Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763e9895",
   "metadata": {},
   "source": [
    "#### S - 1.4.1 Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c924e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 20\n",
    "batch_size = 32\n",
    "sample_interval = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000e6242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stamp(msg:str, time):\n",
    "    print(f'{msg} - {time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783a8ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time():\n",
    "    return time.ctime(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336160f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(iteraions:int, batch_size:int, sample_interval:int):\n",
    "    collection = read_collection(image_path)\n",
    "    image_count = 0\n",
    "    \n",
    "    # Labels \n",
    "    time_stamp(\"Generating labels ...\", get_time())\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    fake_labels = np.zeros((batch_size, 1))\n",
    "    time_stamp(\"Finishing ...\", get_time())\n",
    "    \n",
    "    # Training\n",
    "    for iteration in range(iterations):\n",
    "        time_stamp(f'Iteration {iteration} of {iterations}', get_time())\n",
    "        \n",
    "        # Collect batch\n",
    "        time_stamp(\"Collecting images ...\", get_time())\n",
    "        random_indicies =  np.random.choice(len(collection), size=200, replace=False)\n",
    "        real_image_batch = np.array([collection[i] for i in random_indicies]) / 127.5 - 1.0 # rescale [-1,1]\n",
    "        time_stamp(\"Finishing ...\", get_time())\n",
    "\n",
    "        # Random batch of real images\n",
    "        batch_of_real_indecies = np.random.randint(0, real_image_batch.shape[0], batch_size) # 0 - shape, # of ints\n",
    "        batch_of_real_imgs = real_image_batch[batch_of_real_indecies]\n",
    "        \n",
    "        # Random batch of fake images\n",
    "        z_fake = np.random.normal(0, 1, (batch_size, 512))\n",
    "        generated_images = generator.predict(z_fake)\n",
    "        \n",
    "        # Train Discriminator -> [Loss, Accuracy]\n",
    "        time_stamp(\"Training discriminator ...\", get_time())\n",
    "        discriminator_real_loss = discriminator.train_on_batch(batch_of_real_imgs, real_labels)       \n",
    "        discriminator_fake_loss = discriminator.train_on_batch(generated_images, fake_labels)\n",
    "        \n",
    "        # Get Discriminator loss and accuracy\n",
    "        discriminator_loss, accuracy = 0.5 * np.add(discriminator_real_loss, discriminator_fake_loss)\n",
    "        \n",
    "        # Train Generator\n",
    "        time_stamp(\"Training generator ...\", get_time())\n",
    "        z_fake = np.random.normal(0, 1, (batch_size, 512))\n",
    "        generated_images = generator.predict(z_fake)\n",
    "        \n",
    "        \n",
    "        # Get Generator loss and accuracy\n",
    "        gan_loss = gan.train_on_batch(z_fake, real_labels)\n",
    "        time_stamp(f'Epoch time {iteration}', get_time())\n",
    "        \n",
    "        # Progress output\n",
    "        if (iteration + 1) % sample_interval == 0:\n",
    "            print(\"%d [D loss: %f, acc.:%.2f%%] [G loss: %f]\" % (iteration + 1, discriminator_loss, 100.0* accuracy, gan_loss))\n",
    "            \n",
    "            # Generate random images\n",
    "            z_generated = np.random.randint(0, 1, (3*3, z_dim))\n",
    "            generate_images = generator.predict(z_generated)\n",
    "            generate_images = 0.5 * generate_images + 0.5\n",
    "            \n",
    "            # Plot\n",
    "            fig = plt.figure(figsize= (3, 3)) \n",
    "            fig, axs = plt.subplots(3, 3, sharex=True, sharey=True)\n",
    "            cnt = 0 \n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    axs[i, j].imshow(generate_images[cnt]) # get image from batch at index 'i'\n",
    "                    cnt += 1\n",
    "            plt.savefig(f'iteration{image_count}-gan.png')\n",
    "            image_count += 1\n",
    "            plt.show()\n",
    "    generator.save('./generator_model')\n",
    "    discriminator.save('./discriminator_model')\n",
    "    gan.save('./gan_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dcfa9b",
   "metadata": {},
   "source": [
    "#### Training the network\n",
    "```python\n",
    "train_gan(iterations, batch_size, sample_interval)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda5cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan(iterations, batch_size, sample_interval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 97.85,
   "position": {
    "height": "119.85px",
    "left": "1014px",
    "right": "20px",
    "top": "14px",
    "width": "343px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
