{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338e80fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from skimage import io\n",
    "from skimage.io import imread_collection\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import shutil\n",
    "import PIL\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cae80d",
   "metadata": {},
   "source": [
    "## Fetch Data (Images)\n",
    "We begin by fetching a dataset of 10,000 images from [thispersondoesnotexistcom](https://www.thispersondoesnotexist.com). We do so by requesting from the endpoint `thispersondoesnotexist.com/images` 10,000 (k) times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a4fc0",
   "metadata": {},
   "source": [
    "#### Declare Paths & File Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b5767",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./data/training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074934ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_img_type = \"png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8546c95b",
   "metadata": {},
   "source": [
    "#### Saving an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefbd236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(image, count):\n",
    "        with open(f'{image_path}/img_{count}.{current_img_type}', 'wb') as f:\n",
    "            f.write(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6566605a",
   "metadata": {},
   "source": [
    "#### Scraping images from `thispersondoesnotexists.com`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71888d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_images(k: int, folder_name: str):\n",
    "    \"\"\" \n",
    "    Fetch images from thispersondoesnotexist.com\n",
    "    \n",
    "    :param k: number of images to fetch\n",
    "    :param folder_name: name of folder to save images to\n",
    "    \"\"\"\n",
    "    if k < 1:\n",
    "        return 0\n",
    "    \n",
    "    # Locals\n",
    "    count = 0\n",
    "    endpoint = 'image'\n",
    "    url = f'https://thispersondoesnotexist.com/{endpoint}'\n",
    "    while count < k:\n",
    "        image = requests.get(url).content\n",
    "        save_image(image)\n",
    "        count += 1\n",
    "        \n",
    "        # A time.sleep(x) is recommended to avoid latency errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5865ccc",
   "metadata": {},
   "source": [
    "If we'd like to scrape the images, simply call\n",
    "```python\n",
    "fetch_images(k=10_000, folder_name='training')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1147f81",
   "metadata": {},
   "source": [
    "## Validating image\n",
    "We should validate wether the image exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072e1056",
   "metadata": {},
   "source": [
    "#### Reading an Image\n",
    "Uses `skimage` to read image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f337f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(folder_name:str, image_name:str, img_type:str) -> np.ndarray:\n",
    "    return io.imread(f'{folder_name}/{image_name}.{img_type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50eac97",
   "metadata": {},
   "source": [
    "The following example reads in an image:\n",
    "\n",
    "```python\n",
    "read_image('data/training', 'img_3', 'png')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bf41d3",
   "metadata": {},
   "source": [
    "#### Checking whether an images exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a623c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_exists(folder_name:str) -> bool:\n",
    "    \"\"\" \n",
    "    Check whether an image exists in folder_name\n",
    "    \n",
    "    :param folder_name: folder in which dataset images are located\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Default image 0\n",
    "        image = read_image(image_path,'img_0', 0)\n",
    "        return True\n",
    "    except:\n",
    "        print(f'Image \"img_0.{current_img_type}\" in {folder_name} not found')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66348ebe",
   "metadata": {},
   "source": [
    "## Showing a batch\n",
    "We can see a random batch of images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(batch):\n",
    "    \n",
    "    # Default batch_size of 3\n",
    "    images = np.random.randint(low=0, high=len(batch), size=9) # get random indices\n",
    "    fig = plt.figure(figsize= (3, 3)) \n",
    "    fig, axs = plt.subplots(3,3, sharex=True, sharey=True)\n",
    "    cnt = 0 \n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            axs[i, j].imshow(batch[images[cnt]]) # get image from batch at index 'i'\n",
    "            cnt += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5374b4f3",
   "metadata": {},
   "source": [
    "### Image Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23edd20",
   "metadata": {},
   "source": [
    "#### Reading collection of images from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80adab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_collection(folder_name:str) -> io.collection.ImageCollection:\n",
    "    return imread_collection(f'./{folder_name}/*.{current_img_type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b5d77e",
   "metadata": {},
   "source": [
    "We read and store the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = read_collection(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e7510b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc84282",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3218f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4618b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(collection[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e265d5",
   "metadata": {},
   "source": [
    "### Resizing Images\n",
    "As we can see, all images fetched are $w \\times h \\times c$, it is necessary we resize these into smaller dimensions to efficiently approach this DCGAN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3239c28b",
   "metadata": {},
   "source": [
    "We import `CV2` to resize the images in `./images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda1943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a00d776",
   "metadata": {},
   "source": [
    "We now resize every image in the `collection` and update them with given the new dimensions. All images in `collection` are named as their appropriate index in this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8397865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_directory(folder_name: str):\n",
    "    if not os.path.exists(f'./{folder_name}'):\n",
    "        os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3e733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, size) -> PIL.Image.Image:\n",
    "    resized_image = cv2.resize(image, dsize=size, interpolation=cv2.INTER_CUBIC)\n",
    "    return Image.fromarray(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b972bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_collection(folder_name:str, file_name:str, collection):\n",
    "    make_dir(folder_name)\n",
    "        \n",
    "    for i in range(len(collection)): \n",
    "        new_image = resize_image(collection[i], (128, 128)) \n",
    "        new_image.save(f'./{file_name}/img_{i}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159fdb0",
   "metadata": {},
   "source": [
    "### Neural Network - 1.0\n",
    "We begin by definning attributes. All images in the dataset are from [thispersondoesnotexistcom](https://www.thispersondoesnotexist.com), therefore all images are $1024 \\times 1024$ with $3$ channels. However, our sizing may be $w \\times h \\times c$ if resized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e13c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = collection[0].shape[0]\n",
    "cols = collection[0].shape[1]\n",
    "channels = collection[0].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65468597",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (rows, cols, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963eae70",
   "metadata": {},
   "source": [
    "`z_dim` represents the dimenions of the noise vector to be inputed into the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e6386",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7253c8b7",
   "metadata": {},
   "source": [
    "We first import libraries to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a6545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Dense, Flatten, Reshape, Conv2DTranspose, UpSampling2D, Activation, Conv2D, BatchNormalization, UpSampling2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 128 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9138c4b2",
   "metadata": {},
   "source": [
    "We implement the schematics for $G(z)$ for generating $1024 \\times 1024$ images from [Marchesi, Marco. (2017). Megapixel Size Image Creation using Generative Adversarial Networks.](https://www.researchgate.net/publication/317300265_Megapixel_Size_Image_Creation_using_Generative_Adversarial_Networks), [Karras, Aila. (2018). Progressive Growing of GANs for Improved Quality Stability, and Variation.](https://arxiv.org/pdf/1710.10196.pdf). Our approach will be different. Assistance from these papers is taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934dc84d",
   "metadata": {},
   "source": [
    "#### Model to Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_png(model, file_name:str):\n",
    "    plot_model(model, to_file=f'{file_name}.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc2ff98",
   "metadata": {},
   "source": [
    "#### Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(z) -> keras.models.Sequential:\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input Latent vector\n",
    "    model.add(Dense(4*4*128, input_dim=z))\n",
    "    model.add(Reshape((4, 4, 128)))\n",
    "    \n",
    "    # Conv\n",
    "    model.add(Conv2DTranspose(128, kernel_size=4, strides=4, padding='valid'))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2DTranspose(64, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2DTranspose(32, kernel_size=3, strides=4, padding='same'))   \n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2DTranspose(16, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2DTranspose(3, kernel_size=3, strides=2, padding='same'))    \n",
    "    model.add(Activation('tanh'))\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33709cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generator(z_dim:int):\n",
    "    gen = create_generator(z_dim)\n",
    "    noise = tf.random.normal([1, z_dim])\n",
    "    img = gen.predict(noise)\n",
    "    img = tf.reshape(img, shape=(img.shape[1], img.shape[2], img.shape[3]))\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4675fa1",
   "metadata": {},
   "source": [
    "To test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdceafd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator(z_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6565f23b",
   "metadata": {},
   "source": [
    "#### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4350700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator(img_shape) -> keras.models.Sequential:\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(3, kernel_size=1, padding='same', input_shape=img_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(3, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Conv 1.0\n",
    "    model.add(Conv2D(16, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # Conv 2.0\n",
    "    model.add(Conv2D(32, kernel_size=2, strides=2, padding='valid'))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Conv 3.0\n",
    "    model.add(Conv2D(64, kernel_size=2, strides=2, padding='valid'))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Conv 3.0\n",
    "    model.add(Conv2D(128, kernel_size=2, strides=2, padding='valid'))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Conv 4.0\n",
    "    model.add(Conv2D(128, kernel_size=2, strides=2, padding='valid'))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=2, strides=2, padding='valid'))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Conv 5.0\n",
    "    model.add(Conv2D(128, kernel_size=2, strides=2, padding='valid'))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "              \n",
    "    # Finalized\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf2e86e",
   "metadata": {},
   "source": [
    "#### Set up (S) - 1.1 Create\n",
    "We begin by initializing the discriminator and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_generator(z=z_dim)\n",
    "discriminator = create_discriminator(img_shape=image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c354a60c",
   "metadata": {},
   "source": [
    "#### S - 1.2 Compile \n",
    "We now compile both models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed9c599",
   "metadata": {},
   "source": [
    "##### Generator Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6894eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(learning_rate=0.0020))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c608710b",
   "metadata": {},
   "source": [
    "##### Discriminator Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89913b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Adam(learning_rate=0.0020),\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d07b72",
   "metadata": {},
   "source": [
    "#### S - 1.3 Disable Discriminator Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7864a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68edf2e8",
   "metadata": {},
   "source": [
    "Alternatively, if we wanted to get the models as an image, we'd do:\n",
    "```python\n",
    "plot_model(discriminator, to_file='discriminator.png', show_shapes=True, show_dtype=True, show_layer_names=True)\n",
    "\n",
    "plot_model(generator, to_file='generator.png', show_shapes=True, show_dtype=True, show_layer_names=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f607b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCGAN(generator, discriminator) -> keras.models.Sequential:\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130ff932",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = DCGAN(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763e9895",
   "metadata": {},
   "source": [
    "#### S - 1.4.1 Params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c965084",
   "metadata": {},
   "source": [
    "#### Time Stamping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae5e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stamp(msg:str, time):\n",
    "    print(f'{msg} - {time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e86c6e",
   "metadata": {},
   "source": [
    "#### Getting current time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae6e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time() -> time.ctime:\n",
    "    return time.ctime(time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d72d9b5",
   "metadata": {},
   "source": [
    "#### Training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c924e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 15000\n",
    "batch_size = 64\n",
    "sample_interval = 100\n",
    "folder_name = 'model-02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7b7f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_losses = []\n",
    "gan_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336160f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(iterations:int, batch_size:int, sample_interval:int, folder_name:str):\n",
    "    data_images = read_collection(image_path)\n",
    "    image_count = 0\n",
    "    \n",
    "    # Labels \n",
    "    time_stamp(\"Generating labels ...\", get_time())\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    fake_labels = np.zeros((batch_size, 1))\n",
    "    time_stamp(\"Finishing ...\", get_time())\n",
    "    \n",
    "    make_directory(folder_name)\n",
    "    make_directory(f'{folder_name}/predictions')\n",
    "    \n",
    "    # Training\n",
    "    for iteration in range(iterations):\n",
    "        # time_stamp(f'Iteration {iteration} of {iterations}', get_time())\n",
    "        \n",
    "        # Collect batch\n",
    "        random_indicies =  np.random.choice(len(data_images), size=batch_size, replace=False)\n",
    "        real_image_batch = np.array([data_images[i] for i in random_indicies]) / 127.5 - 1.0 # rescale [-1,1]\n",
    "        \n",
    "        # Random batch of fake images\n",
    "        z_fake = tf.random.normal([batch_size, 128])\n",
    "\n",
    "        generated_images = generator.predict(z_fake)\n",
    "        \n",
    "        # Train Discriminator -> [Loss, Accuracy]\n",
    "        discriminator_real_loss = discriminator.train_on_batch(real_image_batch, real_labels)       \n",
    "        discriminator_fake_loss = discriminator.train_on_batch(generated_images, fake_labels)\n",
    "        \n",
    "        # Get Discriminator loss and accuracy\n",
    "        discriminator_loss, accuracy = 0.5 * np.add(discriminator_real_loss, discriminator_fake_loss)\n",
    "        \n",
    "        # Train Generator\n",
    "        z_fake = tf.random.normal([batch_size, 128])\n",
    "        generated_images = generator.predict(z_fake)\n",
    "        \n",
    "        \n",
    "        # Get Generator loss and accuracy\n",
    "        gan_loss = gan.train_on_batch(z_fake, real_labels)\n",
    "        \n",
    "        discriminator_losses.append(discriminator_loss)\n",
    "        gan_losses.append(gan_loss)\n",
    "        # Progress output\n",
    "        if (iteration + 1) % sample_interval == 0:\n",
    "            print(\"Iteration %d [D loss: %f, acc.:%.2f%%] [G loss: %f]\" % (iteration + 1, discriminator_loss, 100.0* accuracy, gan_loss))\n",
    "            \n",
    "            # Generate random images\n",
    "            z_generated = tf.random.normal([3*3, 128])\n",
    "            generate_images = generator.predict(z_generated)\n",
    "            generate_images = 0.5 * generate_images + 0.5\n",
    "            \n",
    "            # Plot\n",
    "            fig = plt.figure(figsize= (3, 3)) \n",
    "            fig, axs = plt.subplots(3, 3, sharex=True, sharey=True)\n",
    "            cnt = 0 \n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    axs[i, j].imshow(generate_images[cnt]) # get image from batch at index 'i'\n",
    "                    cnt += 1\n",
    "            plt.savefig(f'./{folder_name}/predictions/iteration-{image_count}.png')\n",
    "            image_count += 1\n",
    "            plt.show()\n",
    "    generator.save(f'./{folder_name}/generator')\n",
    "    discriminator.save(f'./{folder_name}/discriminator')\n",
    "    gan.save(f'./{folder_name}/gan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dcfa9b",
   "metadata": {},
   "source": [
    "#### Training the network\n",
    "```python\n",
    "train_gan(iterations, batch_size, sample_interval)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e66dce4",
   "metadata": {},
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda5cbbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_gan(iterations, batch_size, sample_interval, folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gan_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea171e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(discriminator_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ccc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_image_01 = tf.random.normal([1, 128], mean=0, stddev=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_gen_image_01 = generator.predict(fake_image_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_gen_image_01 = 0.5 * fake_gen_image_01 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d910dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fake_gen_image_01[0, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52246c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 97.85,
   "position": {
    "height": "119.85px",
    "left": "1047px",
    "right": "20px",
    "top": "7px",
    "width": "343px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
